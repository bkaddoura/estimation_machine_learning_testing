{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e5f602d-0241-4f0e-9aaa-aedc110ae8d0",
   "metadata": {},
   "source": [
    "## DSI-06 Homework 3: ANSWERS\n",
    "From Chapter 4, found on pages 196-197 of ISLP\n",
    "\n",
    "*This question should be answered using the `Weekly` data set, which is part of the ISLP package. This data is similar in nature to the Smarket data from this section's in-class exercises, except that it contains 1089 weekly returns for 21 years, from the beginning of 1990 to the end of 2010.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af43c39d-5b12-4cd9-82a9-facb32c835de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3.205160</td>\n",
       "      <td>2.969</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2010</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>4.242568</td>\n",
       "      <td>1.281</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>4.835082</td>\n",
       "      <td>0.283</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4.454044</td>\n",
       "      <td>1.034</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>2.707105</td>\n",
       "      <td>0.069</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0     1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1     1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2     1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3     1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4     1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up\n",
       "...    ...    ...    ...    ...    ...    ...       ...    ...       ...\n",
       "1084  2010 -0.861  0.043 -2.173  3.599  0.015  3.205160  2.969        Up\n",
       "1085  2010  2.969 -0.861  0.043 -2.173  3.599  4.242568  1.281        Up\n",
       "1086  2010  1.281  2.969 -0.861  0.043 -2.173  4.835082  0.283        Up\n",
       "1087  2010  0.283  1.281  2.969 -0.861  0.043  4.454044  1.034        Up\n",
       "1088  2010  1.034  0.283  1.281  2.969 -0.861  2.707105  0.069        Up\n",
       "\n",
       "[1089 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import specific objects\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)\n",
    "from ISLP import load_data\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "Weekly = load_data('Weekly')\n",
    "Weekly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c5ccd47-ca85-4e62-b0e1-0b429f2730a8",
   "metadata": {},
   "source": [
    "a) Produce some numerical and graphical summaries of the `Weekly` data. Do there appear to be any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9f5185-9cb5-4da8-a51a-02a41f5048c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Year         Lag1         Lag2         Lag3         Lag4  \\\n",
      "count  1089.000000  1089.000000  1089.000000  1089.000000  1089.000000   \n",
      "mean   2000.048669     0.150585     0.151079     0.147205     0.145818   \n",
      "std       6.033182     2.357013     2.357254     2.360502     2.360279   \n",
      "min    1990.000000   -18.195000   -18.195000   -18.195000   -18.195000   \n",
      "25%    1995.000000    -1.154000    -1.154000    -1.158000    -1.158000   \n",
      "50%    2000.000000     0.241000     0.241000     0.241000     0.238000   \n",
      "75%    2005.000000     1.405000     1.409000     1.409000     1.409000   \n",
      "max    2010.000000    12.026000    12.026000    12.026000    12.026000   \n",
      "\n",
      "              Lag5       Volume        Today  \n",
      "count  1089.000000  1089.000000  1089.000000  \n",
      "mean      0.139893     1.574618     0.149899  \n",
      "std       2.361285     1.686636     2.356927  \n",
      "min     -18.195000     0.087465   -18.195000  \n",
      "25%      -1.166000     0.332022    -1.154000  \n",
      "50%       0.234000     1.002680     0.241000  \n",
      "75%       1.405000     2.053727     1.405000  \n",
      "max      12.026000     9.328214    12.026000  \n"
     ]
    }
   ],
   "source": [
    "# Use the describe() function to obtain basic summary statistics for each variable\n",
    "print(Weekly.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86001139-f7c5-43d9-b10a-93a59e810cd4",
   "metadata": {},
   "source": [
    "b) Use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors. Do not forget to drop missing values due to lag creation. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e034864-89b7-4854-a5a3-87d8450515bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summarize(\u001b[43mresults\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "summarize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dcf794-503d-4ffd-8501-3b2b9afa9a3e",
   "metadata": {},
   "source": [
    "c) Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fae233-67a4-4b81-ad9e-63efd6fbf582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "y_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e9220-055f-4135-80c4-f288f65e8978",
   "metadata": {},
   "source": [
    "d) Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag2 as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from 2009 and 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aed944-4885-45ec-8f14-2725ccc2455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216ddf1-fe11-4828-91cd-602dcc99f110",
   "metadata": {},
   "source": [
    "e) Repeat (d) using LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f61bb3-e580-44d8-bdf2-fd1df2956720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1aae8-9bd0-4d41-8bed-863ff0a2117f",
   "metadata": {},
   "source": [
    "f) Repeat (d) using QDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6063f-c52e-4eba-a930-8aaa4ed80c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd84667-3df1-4f84-b2c6-c8ded360c91b",
   "metadata": {},
   "source": [
    "g) Repeat (d) using KNN with K = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abebebc-4052-4d28-a1cd-1e9c69011d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27d831-0188-4381-8deb-218ec062d4f1",
   "metadata": {},
   "source": [
    "h) Repeat (d) using naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c27b5f-8296-4b07-b67d-6482ca851cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fdba9-6143-41c7-a3f6-d147170192f9",
   "metadata": {},
   "source": [
    "i) Which of these methods appears to provide the best results on this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ceabd-ddaf-4779-b6f9-cb604c24fe10",
   "metadata": {},
   "source": [
    "j) Experiment with different combinations of predictors, including possible transformations and interactions, for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data. Note that you should also experiment with values for K in the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f35da6-2f96-448b-8aa1-8f5607c25e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85e247",
   "metadata": {},
   "source": [
    "Additional Practice Questions: \n",
    "- Explain the difference between MLR and OLS to a non-technical audience. \n",
    "- How would you describe this exercise in an interview to both a technical and non-technical interviewer?\n",
    "- What are the key insights you would want to show? \n",
    "- Can you think of a business context where this exercise would have applications?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

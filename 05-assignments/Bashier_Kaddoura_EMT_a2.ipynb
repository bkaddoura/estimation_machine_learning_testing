{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db0d7a3-39b9-4498-85cb-d9d75f914304",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc97cd7-933f-4bac-804a-1f2cf85ebad6",
   "metadata": {},
   "source": [
    "This assignment is due on __Wednesday March 20, by 11:59PM\t__. It pertains to content taught in classes 4-5.\n",
    "\n",
    "This assignment should be completed in Python, and an PDF file should be submitted, containing both code and written answers. If you like, you may create your own Jupyter Notebook file from scratch, but it is likely easier to modify this one.\n",
    "\n",
    "As before, questions that require identification and/or interpretation will not penalized for brevity of response: if a question can be answered with 'yes/no', or a numeric value, you may simply state as much. If you incorporate code from the internet (which is not required and generally not advisable), please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "If you like, you may collaborate with others in the class. If you choose to do so, please indicate with whom you have worked at the top of your PDF. Separate submissions are required.\n",
    "\n",
    "Any questions can be addressed to Kamilah ([kamilah.ebrahim@mail.utoronto.ca]()) and/or Ananya ([ananya.jha@mail.utoronto.ca]()) and/or Vishnou ([vishnouvina@cs.toronto.edu]()) before the due-date. Please submit your assignments through your Drive Folder.\n",
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "589d262b-0089-4b1a-821d-d55570e0d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: l0bnb in c:\\users\\bash\\documents\\github\\estimation_machine_learning_testing\\emtenv\\lib\\site-packages (1.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\bash\\documents\\github\\estimation_machine_learning_testing\\emtenv\\lib\\site-packages (from l0bnb) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\bash\\documents\\github\\estimation_machine_learning_testing\\emtenv\\lib\\site-packages (from l0bnb) (1.12.0)\n",
      "Requirement already satisfied: numba>=0.53.1 in c:\\users\\bash\\documents\\github\\estimation_machine_learning_testing\\emtenv\\lib\\site-packages (from l0bnb) (0.59.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\bash\\documents\\github\\estimation_machine_learning_testing\\emtenv\\lib\\site-packages (from numba>=0.53.1->l0bnb) (0.42.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import specific objects\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.model_selection as skm\n",
    "from statsmodels.stats.outliers_influence \\\n",
    "     import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "%pip install l0bnb\n",
    "from l0bnb import fit_path\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "\n",
    "# Install, import, and load specific package\n",
    "%pip install faraway > nul 2>&1 # \"> nul 2>&1\" means that the install messages have been surpressed\n",
    "import faraway as fw\n",
    "import faraway.datasets.fat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21283675-9b75-4413-89c2-0890ceb198b8",
   "metadata": {},
   "source": [
    "### Question 1: Regularization via best subset selection\n",
    "\n",
    "First, we'll use the `swiss` dataset, which is a built-in dataset in R, but can be added to Python. As always, start by reviewing a description of the dataset, by typing `df` in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9b3824c-e20a-4709-b7e1-a094bd0841c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fertility</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Examination</th>\n",
       "      <th>Education</th>\n",
       "      <th>Catholic</th>\n",
       "      <th>Infant.Mortality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownames</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Courtelary</th>\n",
       "      <td>80.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>9.96</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delemont</th>\n",
       "      <td>83.1</td>\n",
       "      <td>45.1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>84.84</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Franches-Mnt</th>\n",
       "      <td>92.5</td>\n",
       "      <td>39.7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.40</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moutier</th>\n",
       "      <td>85.8</td>\n",
       "      <td>36.5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>33.77</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuveville</th>\n",
       "      <td>76.9</td>\n",
       "      <td>43.5</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.16</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Porrentruy</th>\n",
       "      <td>76.1</td>\n",
       "      <td>35.3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>90.57</td>\n",
       "      <td>26.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Broye</th>\n",
       "      <td>83.8</td>\n",
       "      <td>70.2</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>92.85</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glane</th>\n",
       "      <td>92.4</td>\n",
       "      <td>67.8</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>97.16</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gruyere</th>\n",
       "      <td>82.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>97.67</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sarine</th>\n",
       "      <td>82.9</td>\n",
       "      <td>45.2</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>91.38</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veveyse</th>\n",
       "      <td>87.1</td>\n",
       "      <td>64.5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>98.61</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aigle</th>\n",
       "      <td>64.1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>8.52</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aubonne</th>\n",
       "      <td>66.9</td>\n",
       "      <td>67.5</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>2.27</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avenches</th>\n",
       "      <td>68.9</td>\n",
       "      <td>60.7</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>4.43</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cossonay</th>\n",
       "      <td>61.7</td>\n",
       "      <td>69.3</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2.82</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Echallens</th>\n",
       "      <td>68.3</td>\n",
       "      <td>72.6</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>24.20</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grandson</th>\n",
       "      <td>71.7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3.30</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lausanne</th>\n",
       "      <td>55.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>12.11</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Vallee</th>\n",
       "      <td>54.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>2.15</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lavaux</th>\n",
       "      <td>65.1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>2.84</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morges</th>\n",
       "      <td>65.5</td>\n",
       "      <td>59.8</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>5.23</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moudon</th>\n",
       "      <td>65.0</td>\n",
       "      <td>55.1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4.52</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nyone</th>\n",
       "      <td>56.6</td>\n",
       "      <td>50.9</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>15.14</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbe</th>\n",
       "      <td>57.4</td>\n",
       "      <td>54.1</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>4.20</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oron</th>\n",
       "      <td>72.5</td>\n",
       "      <td>71.2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payerne</th>\n",
       "      <td>74.2</td>\n",
       "      <td>58.1</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>5.23</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paysd'enhaut</th>\n",
       "      <td>72.0</td>\n",
       "      <td>63.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.56</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rolle</th>\n",
       "      <td>60.5</td>\n",
       "      <td>60.8</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>7.72</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vevey</th>\n",
       "      <td>58.3</td>\n",
       "      <td>26.8</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>18.46</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yverdon</th>\n",
       "      <td>65.4</td>\n",
       "      <td>49.5</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>6.10</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conthey</th>\n",
       "      <td>75.5</td>\n",
       "      <td>85.9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>99.71</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entremont</th>\n",
       "      <td>69.3</td>\n",
       "      <td>84.9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>99.68</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herens</th>\n",
       "      <td>77.3</td>\n",
       "      <td>89.7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martigwy</th>\n",
       "      <td>70.5</td>\n",
       "      <td>78.2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>98.96</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthey</th>\n",
       "      <td>79.4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>98.22</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St Maurice</th>\n",
       "      <td>65.0</td>\n",
       "      <td>75.9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>99.06</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sierre</th>\n",
       "      <td>92.2</td>\n",
       "      <td>84.6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>99.46</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sion</th>\n",
       "      <td>79.3</td>\n",
       "      <td>63.1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>96.83</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boudry</th>\n",
       "      <td>70.4</td>\n",
       "      <td>38.4</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>5.62</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Chauxdfnd</th>\n",
       "      <td>65.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>13.79</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Le Locle</th>\n",
       "      <td>72.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>11.22</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuchatel</th>\n",
       "      <td>64.4</td>\n",
       "      <td>17.6</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>16.92</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Val de Ruz</th>\n",
       "      <td>77.6</td>\n",
       "      <td>37.6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4.97</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ValdeTravers</th>\n",
       "      <td>67.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>8.65</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V. De Geneve</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>37</td>\n",
       "      <td>53</td>\n",
       "      <td>42.34</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rive Droite</th>\n",
       "      <td>44.7</td>\n",
       "      <td>46.6</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>50.43</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rive Gauche</th>\n",
       "      <td>42.8</td>\n",
       "      <td>27.7</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>58.33</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fertility  Agriculture  Examination  Education  Catholic  \\\n",
       "rownames                                                                 \n",
       "Courtelary         80.2         17.0           15         12      9.96   \n",
       "Delemont           83.1         45.1            6          9     84.84   \n",
       "Franches-Mnt       92.5         39.7            5          5     93.40   \n",
       "Moutier            85.8         36.5           12          7     33.77   \n",
       "Neuveville         76.9         43.5           17         15      5.16   \n",
       "Porrentruy         76.1         35.3            9          7     90.57   \n",
       "Broye              83.8         70.2           16          7     92.85   \n",
       "Glane              92.4         67.8           14          8     97.16   \n",
       "Gruyere            82.4         53.3           12          7     97.67   \n",
       "Sarine             82.9         45.2           16         13     91.38   \n",
       "Veveyse            87.1         64.5           14          6     98.61   \n",
       "Aigle              64.1         62.0           21         12      8.52   \n",
       "Aubonne            66.9         67.5           14          7      2.27   \n",
       "Avenches           68.9         60.7           19         12      4.43   \n",
       "Cossonay           61.7         69.3           22          5      2.82   \n",
       "Echallens          68.3         72.6           18          2     24.20   \n",
       "Grandson           71.7         34.0           17          8      3.30   \n",
       "Lausanne           55.7         19.4           26         28     12.11   \n",
       "La Vallee          54.3         15.2           31         20      2.15   \n",
       "Lavaux             65.1         73.0           19          9      2.84   \n",
       "Morges             65.5         59.8           22         10      5.23   \n",
       "Moudon             65.0         55.1           14          3      4.52   \n",
       "Nyone              56.6         50.9           22         12     15.14   \n",
       "Orbe               57.4         54.1           20          6      4.20   \n",
       "Oron               72.5         71.2           12          1      2.40   \n",
       "Payerne            74.2         58.1           14          8      5.23   \n",
       "Paysd'enhaut       72.0         63.5            6          3      2.56   \n",
       "Rolle              60.5         60.8           16         10      7.72   \n",
       "Vevey              58.3         26.8           25         19     18.46   \n",
       "Yverdon            65.4         49.5           15          8      6.10   \n",
       "Conthey            75.5         85.9            3          2     99.71   \n",
       "Entremont          69.3         84.9            7          6     99.68   \n",
       "Herens             77.3         89.7            5          2    100.00   \n",
       "Martigwy           70.5         78.2           12          6     98.96   \n",
       "Monthey            79.4         64.9            7          3     98.22   \n",
       "St Maurice         65.0         75.9            9          9     99.06   \n",
       "Sierre             92.2         84.6            3          3     99.46   \n",
       "Sion               79.3         63.1           13         13     96.83   \n",
       "Boudry             70.4         38.4           26         12      5.62   \n",
       "La Chauxdfnd       65.7          7.7           29         11     13.79   \n",
       "Le Locle           72.7         16.7           22         13     11.22   \n",
       "Neuchatel          64.4         17.6           35         32     16.92   \n",
       "Val de Ruz         77.6         37.6           15          7      4.97   \n",
       "ValdeTravers       67.6         18.7           25          7      8.65   \n",
       "V. De Geneve       35.0          1.2           37         53     42.34   \n",
       "Rive Droite        44.7         46.6           16         29     50.43   \n",
       "Rive Gauche        42.8         27.7           22         29     58.33   \n",
       "\n",
       "              Infant.Mortality  \n",
       "rownames                        \n",
       "Courtelary                22.2  \n",
       "Delemont                  22.2  \n",
       "Franches-Mnt              20.2  \n",
       "Moutier                   20.3  \n",
       "Neuveville                20.6  \n",
       "Porrentruy                26.6  \n",
       "Broye                     23.6  \n",
       "Glane                     24.9  \n",
       "Gruyere                   21.0  \n",
       "Sarine                    24.4  \n",
       "Veveyse                   24.5  \n",
       "Aigle                     16.5  \n",
       "Aubonne                   19.1  \n",
       "Avenches                  22.7  \n",
       "Cossonay                  18.7  \n",
       "Echallens                 21.2  \n",
       "Grandson                  20.0  \n",
       "Lausanne                  20.2  \n",
       "La Vallee                 10.8  \n",
       "Lavaux                    20.0  \n",
       "Morges                    18.0  \n",
       "Moudon                    22.4  \n",
       "Nyone                     16.7  \n",
       "Orbe                      15.3  \n",
       "Oron                      21.0  \n",
       "Payerne                   23.8  \n",
       "Paysd'enhaut              18.0  \n",
       "Rolle                     16.3  \n",
       "Vevey                     20.9  \n",
       "Yverdon                   22.5  \n",
       "Conthey                   15.1  \n",
       "Entremont                 19.8  \n",
       "Herens                    18.3  \n",
       "Martigwy                  19.4  \n",
       "Monthey                   20.2  \n",
       "St Maurice                17.8  \n",
       "Sierre                    16.3  \n",
       "Sion                      18.1  \n",
       "Boudry                    20.3  \n",
       "La Chauxdfnd              20.5  \n",
       "Le Locle                  18.9  \n",
       "Neuchatel                 23.0  \n",
       "Val de Ruz                20.0  \n",
       "ValdeTravers              19.5  \n",
       "V. De Geneve              18.0  \n",
       "Rive Droite               18.2  \n",
       "Rive Gauche               19.3  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "swiss = sm.datasets.get_rdataset(\"swiss\")\n",
    "df = pd.DataFrame(swiss.data)\n",
    "\n",
    "# Explore the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5e9d10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] # number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473b2bf-8f6b-4370-8d96-1def6e2ee7cf",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "_(i)_ What will be the size (number of observations) of each LOOCV training sample?\n",
    "\n",
    "**46**\n",
    "\n",
    "_(ii)_ What will be the size (number of observations) of each LOOCV testing sample?\n",
    "\n",
    "**1**\n",
    "\n",
    "_(iii)_ How many \"folds\" (i.e., k) will our LOOCV model have?  \n",
    "\n",
    "**47** (number of observations)\n",
    "\n",
    "_(iv)_ Now, fit a linear model, with `Fertility` as the response variable, and all other variables as predictors. Use the `sm.OLS` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cb0abf7-57e2-447c-8f2a-98838401a863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Fertility</td>    <th>  R-squared:         </th> <td>   0.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   19.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 22 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>5.59e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:17:31</td>     <th>  Log-Likelihood:    </th> <td> -156.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    47</td>      <th>  AIC:               </th> <td>   324.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    41</td>      <th>  BIC:               </th> <td>   335.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>   66.9152</td> <td>   10.706</td> <td>    6.250</td> <td> 0.000</td> <td>   45.294</td> <td>   88.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Agriculture</th>      <td>   -0.1721</td> <td>    0.070</td> <td>   -2.448</td> <td> 0.019</td> <td>   -0.314</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Examination</th>      <td>   -0.2580</td> <td>    0.254</td> <td>   -1.016</td> <td> 0.315</td> <td>   -0.771</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Education</th>        <td>   -0.8709</td> <td>    0.183</td> <td>   -4.758</td> <td> 0.000</td> <td>   -1.241</td> <td>   -0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Catholic</th>         <td>    0.1041</td> <td>    0.035</td> <td>    2.953</td> <td> 0.005</td> <td>    0.033</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Infant.Mortality</th> <td>    1.0770</td> <td>    0.382</td> <td>    2.822</td> <td> 0.007</td> <td>    0.306</td> <td>    1.848</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.058</td> <th>  Durbin-Watson:     </th> <td>   1.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.971</td> <th>  Jarque-Bera (JB):  </th> <td>   0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.077</td> <th>  Prob(JB):          </th> <td>   0.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.764</td> <th>  Cond. No.          </th> <td>    807.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &    Fertility     & \\textbf{  R-squared:         } &     0.707   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.671   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     19.76   \\\\\n",
       "\\textbf{Date:}             & Fri, 22 Mar 2024 & \\textbf{  Prob (F-statistic):} &  5.59e-10   \\\\\n",
       "\\textbf{Time:}             &     22:17:31     & \\textbf{  Log-Likelihood:    } &   -156.04   \\\\\n",
       "\\textbf{No. Observations:} &          47      & \\textbf{  AIC:               } &     324.1   \\\\\n",
       "\\textbf{Df Residuals:}     &          41      & \\textbf{  BIC:               } &     335.2   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}            &      66.9152  &       10.706     &     6.250  &         0.000        &       45.294    &       88.536     \\\\\n",
       "\\textbf{Agriculture}      &      -0.1721  &        0.070     &    -2.448  &         0.019        &       -0.314    &       -0.030     \\\\\n",
       "\\textbf{Examination}      &      -0.2580  &        0.254     &    -1.016  &         0.315        &       -0.771    &        0.255     \\\\\n",
       "\\textbf{Education}        &      -0.8709  &        0.183     &    -4.758  &         0.000        &       -1.241    &       -0.501     \\\\\n",
       "\\textbf{Catholic}         &       0.1041  &        0.035     &     2.953  &         0.005        &        0.033    &        0.175     \\\\\n",
       "\\textbf{Infant.Mortality} &       1.0770  &        0.382     &     2.822  &         0.007        &        0.306    &        1.848     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.058 & \\textbf{  Durbin-Watson:     } &    1.454  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.971 & \\textbf{  Jarque-Bera (JB):  } &    0.155  \\\\\n",
       "\\textbf{Skew:}          & -0.077 & \\textbf{  Prob(JB):          } &    0.925  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.764 & \\textbf{  Cond. No.          } &     807.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              Fertility   R-squared:                       0.707\n",
       "Model:                            OLS   Adj. R-squared:                  0.671\n",
       "Method:                 Least Squares   F-statistic:                     19.76\n",
       "Date:                Fri, 22 Mar 2024   Prob (F-statistic):           5.59e-10\n",
       "Time:                        22:17:31   Log-Likelihood:                -156.04\n",
       "No. Observations:                  47   AIC:                             324.1\n",
       "Df Residuals:                      41   BIC:                             335.2\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const               66.9152     10.706      6.250      0.000      45.294      88.536\n",
       "Agriculture         -0.1721      0.070     -2.448      0.019      -0.314      -0.030\n",
       "Examination         -0.2580      0.254     -1.016      0.315      -0.771       0.255\n",
       "Education           -0.8709      0.183     -4.758      0.000      -1.241      -0.501\n",
       "Catholic             0.1041      0.035      2.953      0.005       0.033       0.175\n",
       "Infant.Mortality     1.0770      0.382      2.822      0.007       0.306       1.848\n",
       "==============================================================================\n",
       "Omnibus:                        0.058   Durbin-Watson:                   1.454\n",
       "Prob(Omnibus):                  0.971   Jarque-Bera (JB):                0.155\n",
       "Skew:                          -0.077   Prob(JB):                        0.925\n",
       "Kurtosis:                       2.764   Cond. No.                         807.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =df.drop('Fertility', axis=1)\n",
    "y = df['Fertility']\n",
    "\n",
    "model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9e506",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "F-Stat is low meaning we have some useless variables and can eliminate some.\n",
    "Examination, p value is high; can eliminate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e58fe-2bf9-44f1-8184-494d4d52b79c",
   "metadata": {},
   "source": [
    "_(v)_ Next, perform LOOCV, using the appropriate function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0773d418-870f-4122-bbf0-3fa5f26523ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 47 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n47 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\ISLP\\models\\sklearn_wrap.py\", line 70, in fit\n    self.model_spec_ = self.model_spec.fit(X)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\ISLP\\models\\model_spec.py\", line 312, in fit\n    raise ValueError('each element in a term should be a Feature, Column or identify a column')\nValueError: each element in a term should be a Feature, Column or identify a column\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFertility\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# Response variable\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform LOOCV\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mols_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:450\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    432\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    448\u001b[0m )\n\u001b[1;32m--> 450\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 47 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n47 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\ISLP\\models\\sklearn_wrap.py\", line 70, in fit\n    self.model_spec_ = self.model_spec.fit(X)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\bash\\Documents\\GitHub\\estimation_machine_learning_testing\\emtenv\\Lib\\site-packages\\ISLP\\models\\model_spec.py\", line 312, in fit\n    raise ValueError('each element in a term should be a Feature, Column or identify a column')\nValueError: each element in a term should be a Feature, Column or identify a column\n"
     ]
    }
   ],
   "source": [
    "from ISLP.models import sklearn_sm\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "\n",
    "ols_model = sklearn_sm(sm.OLS, MS(['Agricultrure', 'Examination', 'Education', 'Catholic', 'Infant.Mortality']))\n",
    "\n",
    "# Define predictors and response variable\n",
    "X = df.drop(columns='Fertility') # Predictors (excluding fertility)\n",
    "y = df['Fertility'] # Response variable\n",
    "\n",
    "# Perform LOOCV\n",
    "cv_results = cross_validate(ols_model, X, y, cv=df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76f1994-6d3f-4aa9-8288-5ecd385315bd",
   "metadata": {},
   "source": [
    "_(vi)_ What is the MSE for the LOOCV?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a807b1e0-821b-4bb6-851b-c0ce1d197f6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv_err  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mcv_results\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m cv_err\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv_results' is not defined"
     ]
    }
   ],
   "source": [
    "cv_err  = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb482a-1a25-4370-b8e7-5497ca5baff1",
   "metadata": {},
   "source": [
    "_(vii)_ Run the LOOCV for a second time (no need to repeat the code; simply, run your existing code in in v and vi again). Do you obtain different results? Why or why not?  \n",
    "\n",
    "No, since no randomness is involved.\n",
    "\n",
    "_(viii)_ Manually compute MSE for the linear model (without LOOCV) that you fit with the `sm.OLS` function, in iv. (Hint: recall that MSE is defined as the sum of squared residuals, divided by n. You can \"look inside\" your linear model object to find residual values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfd956ff-1d69-4500-b116-9319958eab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 44.788147456257114\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted values \n",
    "predicted_values = model.predict()\n",
    "\n",
    "# Compute the residuals\n",
    "residuals = y - predicted_values\n",
    "\n",
    "# Compute Mean Squared Error (MSE)\n",
    "MSE = np.sum(residuals**2) / len(y)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f5506-6637-4fbd-994c-0b363082a2cf",
   "metadata": {},
   "source": [
    "_(ix)_ Does the LOOCV-linear model, or the non-validated linear model, appear to have greater error? Why might this be the case?   \n",
    "\n",
    "LOOCV has greater error, it is possible that non-validated linear model is overfit.\n",
    "\n",
    "Imagine that the `swiss` dataset has just announced a major new release, which will include data from all provinces of Europe (not just those in Switzerland), and records all the way to the present day (not just 1888).  \n",
    "\n",
    "_(x)_ Would you choose LOOCV as a validation method for this new release? Why or why not?  \n",
    "\n",
    "No, might be too large for computation.\n",
    "\n",
    "_(xi)_ What validation method might you choose instead?  \n",
    "\n",
    "K-fold CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771ad73",
   "metadata": {},
   "source": [
    "### Question 2: Resampling via Bootstrapping\n",
    "\n",
    "Now, we'll use the `iris` dataset, which we will add to Python using the `statsmodels` library. As always, start by reviewing a description of the dataset, by printing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67cf06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "iris = sm.datasets.get_rdataset('iris', 'datasets')\n",
    "df = pd.DataFrame(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "420a4459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width    Species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f938d",
   "metadata": {},
   "source": [
    "Imagine we are analysts working for a shipping company. The company wants to know the average length of iris' petals, to inform space allotment on an upcoming shipment. The relevant variable in the dataset is `Petal.Length`. \n",
    "\n",
    "_(i)_ Why is it (perhaps) not sufficient to simply calculate the mean of `Petal.Length`? What more information will preforming a bootstrap provide to us?  \n",
    "\n",
    "The simple mean calculation does not provide any indication of how the iris sample mean compares to the true population mean. The bootstrap allows us to quantify uncertainty.\n",
    "\n",
    "_(ii)_ We can perform bootstrapping in Python by defining a simple function using `boot_SE()` for computing the bootstrap standard error. Remember, because bootstrapping involves randomness, we must first set a seed for reproducibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cc5cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func,\n",
    "            D,\n",
    "            n=None,\n",
    "            R=1000,\n",
    "            seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    samples = []\n",
    "    for _ in range(R): \n",
    "        idx = rng.choice(D.index,\n",
    "                         n,\n",
    "                         replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2              \n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844a56d",
   "metadata": {},
   "source": [
    "(iii) Before performing bootstrapping, we need to write our own, specialized function to calculate the statistic of interest: in our case, we want to calculate mean. There is one error (typo) in the function below. Correct the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efba9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(data):\n",
    "\n",
    "    # Calculate the mean of data (which will be a bootstrap sample from 'Petal.Length')\n",
    "    result = data.mean()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d392ed5",
   "metadata": {},
   "source": [
    "\n",
    "_(iv)_ Now that we have our desired function, we can perform the bootstrap. Check out boot_samples() to understand its three required arguments. Remember, because bootstrapping involves randomness, we must first set a seed for reproducibility!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6435e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided function to compute the bootstrap samples\n",
    "def boot_samples(data, func, R):\n",
    "    \n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "    \n",
    "    # Perform bootstrapping\n",
    "    for _ in range(R):\n",
    "        # Generate a bootstrap sample\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        \n",
    "        # Compute the result\n",
    "        result = func(bootstrap_sample)\n",
    "        \n",
    "        # Store the result\n",
    "        results.append(result)\n",
    "    \n",
    "    # Return the standard deviation of the results\n",
    "    return results\n",
    "\n",
    "# Compute the bootstrapped samples\n",
    "boot_se_samples = boot_samples(df['Petal.Length'], my_func, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cfe059",
   "metadata": {},
   "source": [
    "_(v)_ First, What is the original mean value ?\n",
    "\n",
    "Next, let's look _inside_ our bootstrapping to understand the new, bootstrapped sample we have created. Let's review the bootstrapped range, by using `t_range = np.ptp(boot_se_samples)`.\n",
    "\n",
    "_(vii)_. Write code to review the bootstrapped mean value, and the standard deviation of the bootstrapped samples. Compare the mean against its original value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e6071d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686666666666674"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_range = np.ptp(boot_se_samples)\n",
    "t_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a7f9e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.756234"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(boot_se_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02824895",
   "metadata": {},
   "source": [
    "_(viii)_ Next, let's compute 95% confidence intervals, for the mean value of iris petal length. (Hint: use the `np.percentile` function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d9f6357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9873666666666665"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(boot_se_samples, 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e68ff",
   "metadata": {},
   "source": [
    "_(ix)_. Use the plot function to create an histogram of the bootstrapped samples. What does this histogram show ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c1c37a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Complete this\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(boot_se_samples, label='Data')\n",
    "\n",
    "# Add a title\n",
    "plt.title('bootstrap iris petal')\n",
    "\n",
    "# Add a label to the x-axis\n",
    "plt.xlabel('iris length')\n",
    "\n",
    "# Add a label to the y-axis\n",
    "plt.ylabel('samples')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb427819",
   "metadata": {},
   "source": [
    "_(x)_ Given your bootstrapped analysis, what do you recommend to shipping company? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
